{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a7d4db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph,END,add_messages,START\n",
    "from langgraph.types import Command,interrupt\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain_community.vectorstores import Chroma\n",
    "load_dotenv()\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e83356d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"\"\" \n",
    "If I had to pick one, it would be One Piece. The series stands out for its insanely deep lore, interconnected stories, and a massive, vibrant world that continues to expand. The character development is top-notch—Luffy and his crew grow meaningfully over time, and even side characters have rich, detailed backstories. Despite having over 1000 episodes, the plot consistently raises the stakes and delivers satisfying payoffs, which is rare for such long-running series. One Piece also explores themes like freedom, dreams, loyalty, and moral complexity in a nuanced way. That said, Naruto is an incredible series in its own right, especially known for its emotional arcs, legendary battles, and strong coming-of-age narrative. If you prefer tighter pacing and more grounded emotional storytelling—particularly in the original Naruto—then that might be the better fit for you.\n",
    "        \"\"\"\n",
    "        ,metadata={\"source\":\"mygpt/chatgpt\"} #test\n",
    "    ),\n",
    "        Document(\n",
    "        page_content=\"\"\" \n",
    "            naruto is a ninja legend\n",
    "        \"\"\"\n",
    "        ,metadata={\"source\":\"mygpt/naruto\"} #test\n",
    "    ),\n",
    "       Document(\n",
    "        page_content=\"\"\" \n",
    "            luffy is the best main character\n",
    "        \"\"\"\n",
    "        ,metadata={\"source\":\"mygpt/luffy\"} #test\n",
    "    ),\n",
    "    \n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "Vector databases are optimized systems designed for storing and retrieving high-dimensional vector representations of data.\n",
    "These vectors are often the result of embedding text, images, or other data modalities using machine learning models.\n",
    "Instead of matching exact keywords, vector databases enable semantic search by comparing the similarity between vectors.\n",
    "This approach is especially useful in natural language processing, recommendation engines, and other AI applications where contextual meaning matters.\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"wikipedia/vector_databases\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "FAISS, which stands for Facebook AI Similarity Search, is an open-source library developed by Facebook AI Research.\n",
    "It provides efficient algorithms for clustering and nearest neighbor search on dense vectors.\n",
    "FAISS supports both CPU and GPU implementations, allowing it to scale to billions of vectors.\n",
    "It is widely used in industry for powering semantic search, recommendation systems, and AI-powered assistants.\n",
    "Its support for indexing structures like IVF, HNSW, and PQ makes it versatile for trade-offs between speed and accuracy.\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"docs/faiss\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "Chroma is a modern, open-source vector database built specifically for large language model applications.\n",
    "It provides a simple API for adding documents, querying them, and managing embeddings.\n",
    "Chroma integrates seamlessly with LangChain and supports persistent storage, making it ideal for long-term document management.\n",
    "It includes features like namespace separation, filtering by metadata, and fast similarity search across millions of embeddings.\n",
    "Developers can choose to embed documents using OpenAI, HuggingFace, or custom models.\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"chroma/overview\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "In modern AI systems, raw data like text, images, and audio are transformed into embeddings—dense numerical representations of the data.\n",
    "These embeddings capture semantic meaning and allow for efficient similarity comparison.\n",
    "To generate embeddings, models like OpenAI's `text-embedding-ada-002` or HuggingFace's `sentence-transformers` are commonly used.\n",
    "Once generated, these vectors are stored in a vector database for real-time semantic retrieval.\n",
    "This technique powers many LLM use cases such as RAG (Retrieval-Augmented Generation) and intelligent assistants.\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"course/embeddings101\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "Similarity search is the core operation in vector databases, where the goal is to find vectors in the database that are most similar to a query vector.\n",
    "This is typically done using metrics like cosine similarity, Euclidean distance, or dot product.\n",
    "The result is a ranked list of documents that are most relevant to the query in terms of semantic meaning.\n",
    "To improve performance at scale, vector databases use indexing techniques like HNSW (Hierarchical Navigable Small World graphs).\n",
    "These indexes reduce the number of distance computations and allow real-time response for millions of documents.\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"notes/similarity_search\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "db = Chroma.from_documents(documents=docs,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.embed_documents(\"hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee6f9609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'wikipedia/vector_databases'}, page_content='\\nVector databases are optimized systems designed for storing and retrieving high-dimensional vector representations of data.\\nThese vectors are often the result of embedding text, images, or other data modalities using machine learning models.\\nInstead of matching exact keywords, vector databases enable semantic search by comparing the similarity between vectors.\\nThis approach is especially useful in natural language processing, recommendation engines, and other AI applications where contextual meaning matters.\\n'),\n",
       " Document(metadata={'source': 'chroma/overview'}, page_content='\\nChroma is a modern, open-source vector database built specifically for large language model applications.\\nIt provides a simple API for adding documents, querying them, and managing embeddings.\\nChroma integrates seamlessly with LangChain and supports persistent storage, making it ideal for long-term document management.\\nIt includes features like namespace separation, filtering by metadata, and fast similarity search across millions of embeddings.\\nDevelopers can choose to embed documents using OpenAI, HuggingFace, or custom models.\\n'),\n",
       " Document(metadata={'source': 'mygpt/naruto'}, page_content=' \\n            naruto is a ninja legend\\n        ')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":3})\n",
    "retriever.invoke(\"Vector databases are \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ea3a2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_temp = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Answer the following question using this context:{context}\n",
    "        question:{question}\n",
    "     \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9b4e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "rag_chain = prompt_temp | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "69cb373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Annotated\n",
    "from langchain_core.messages import AIMessage,HumanMessage,BaseMessage\n",
    "from langgraph.graph import add_messages,StateGraph,END\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: list[BaseMessage]\n",
    "    documents: list[Document]\n",
    "    on_topic : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "26b74e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class QuestionInTopics(BaseModel):\n",
    "    \"\"\"Boolean value to check if the given question related to the topics\"\"\"\n",
    "\n",
    "    val: str=Field(description=\"Question is about topics listed? if yes -> yes else -> no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "006ef323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def question_classifier_node(state: AgentState):\n",
    "    topics_prompt = \"\"\"\n",
    "    Check if the given question is related to any of the topics\n",
    "    # === Topics ===\n",
    "    # 1. Vector Databases\n",
    "    # 2. FAISS Library\n",
    "    # 3. ChromaDB Overview\n",
    "    # 4. Embeddings & Models\n",
    "    # 5. Similarity Search\n",
    "    # 6. Retrieval-Augmented Generation (RAG)\n",
    "    # 7. LangChain Overview\n",
    "    # 8. HuggingFace Transformers\n",
    "    # 9. HNSW Indexing\n",
    "    # 10.OpenAI Embedding API\n",
    "    # 11.Naruto\n",
    "    # 12.Luffy\n",
    "    \n",
    "\n",
    "    if given question is related even if slightly related to the above topics give yes else give no(respond with only yes or no)\n",
    "    \"\"\"\n",
    "    topics_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",topics_prompt),\n",
    "        (\"human\",\"quesion: {question}\")\n",
    "    ])\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    llm = llm.with_structured_output(QuestionInTopics)\n",
    "    llm_chain = {\n",
    "        \"question\":lambda x:x[\"question\"]\n",
    "        } | topics_template | llm \n",
    "    output=llm_chain.invoke({\"question\":state[\"messages\"][-1]})\n",
    "    state[\"on_topic\"] = output.val\n",
    "    print(state[\"on_topic\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f189b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_topic_route(state:AgentState):\n",
    "    return \"retrieve_node\" if state[\"on_topic\"] == \"yes\" else \"off_topic_response\"\n",
    "\n",
    "\n",
    "def retrieve_node(state:AgentState):\n",
    "    docs = retriever.invoke(state[\"messages\"][-1].content)\n",
    "    state[\"documents\"]=docs\n",
    "    return state\n",
    "\n",
    "def off_topic_response(state:AgentState):\n",
    "    return state[\"messages\"].append(AIMessage(content=\"Sorry the given question is off my boundaries i cannot answer.\"))\n",
    "\n",
    "def answer_node(state:AgentState):\n",
    "    formatted_docs = format_docs(state[\"documents\"])\n",
    "\n",
    "    answer = rag_chain.invoke({\"context\":formatted_docs,\"question\":state[\"messages\"]})\n",
    "\n",
    "    return state[\"messages\"].append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5eb5a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"question_classifier_node\",question_classifier_node)\n",
    "graph.add_node(\"retrieve_node\",retrieve_node)\n",
    "graph.add_node(\"answer_node\",answer_node)\n",
    "graph.add_node(\"off_topic_response\",off_topic_response)\n",
    "\n",
    "graph.add_edge(START,\"question_classifier_node\")\n",
    "graph.add_conditional_edges(\"question_classifier_node\",on_topic_route,{\"retrieve_node\":\"retrieve_node\",\"off_topic_response\":\"off_topic_response\"})\n",
    "graph.add_edge(\"retrieve_node\",\"answer_node\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "36e02d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "{'messages': [HumanMessage(content='why luffy is better than naruto', additional_kwargs={}, response_metadata={}), AIMessage(content='Based on the provided context, it states that \"luffy is the best main character.\" The context does not provide reasons why Luffy is better than Naruto, only that Naruto is \"a ninja legend.\"', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--9d431a5d-482c-499a-b527-9e0c6ca9ef8d-0', usage_metadata={'input_tokens': 178, 'output_tokens': 40, 'total_tokens': 381, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 163}})], 'documents': [Document(metadata={'source': 'mygpt/luffy'}, page_content=' \\n            luffy is the best main character\\n        '), Document(metadata={'source': 'mygpt/naruto'}, page_content=' \\n            naruto is a ninja legend\\n        '), Document(metadata={'source': 'notes/similarity_search'}, page_content='\\nSimilarity search is the core operation in vector databases, where the goal is to find vectors in the database that are most similar to a query vector.\\nThis is typically done using metrics like cosine similarity, Euclidean distance, or dot product.\\nThe result is a ranked list of documents that are most relevant to the query in terms of semantic meaning.\\nTo improve performance at scale, vector databases use indexing techniques like HNSW (Hierarchical Navigable Small World graphs).\\nThese indexes reduce the number of distance computations and allow real-time response for millions of documents.\\n')], 'on_topic': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"messages\":[HumanMessage(content=\"why luffy is better than naruto\")],\n",
    "    \"documents\":[],\n",
    "    \"on_topic\":\"\"\n",
    "}\n",
    "print(app.invoke(initial_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "09a21ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the document text.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "doc = Document(page_content=\"This is the document text.\", metadata={\"source\": \"myfile.pdf\"})\n",
    "\n",
    "# Get the raw text\n",
    "text = doc.page_content\n",
    "print(text)  # Output: This is the document text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "63cc3b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'mygpt/chatgpt'}, page_content=' \\nIf I had to pick one, it would be One Piece. The series stands out for its insanely deep lore, interconnected stories, and a massive, vibrant world that continues to expand. The character development is top-notch—Luffy and his crew grow meaningfully over time, and even side characters have rich, detailed backstories. Despite having over 1000 episodes, the plot consistently raises the stakes and delivers satisfying payoffs, which is rare for such long-running series. One Piece also explores themes like freedom, dreams, loyalty, and moral complexity in a nuanced way. That said, Naruto is an incredible series in its own right, especially known for its emotional arcs, legendary battles, and strong coming-of-age narrative. If you prefer tighter pacing and more grounded emotional storytelling—particularly in the original Naruto—then that might be the better fit for you.\\n        '),\n",
       " Document(metadata={'source': 'mygpt/naruto'}, page_content=' \\n            naruto is a ninja legend\\n        '),\n",
       " Document(metadata={'source': 'notes/similarity_search'}, page_content='\\nSimilarity search is the core operation in vector databases, where the goal is to find vectors in the database that are most similar to a query vector.\\nThis is typically done using metrics like cosine similarity, Euclidean distance, or dot product.\\nThe result is a ranked list of documents that are most relevant to the query in terms of semantic meaning.\\nTo improve performance at scale, vector databases use indexing techniques like HNSW (Hierarchical Navigable Small World graphs).\\nThese indexes reduce the number of distance computations and allow real-time response for millions of documents.\\n')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"why one piece is better than naruto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740d852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed879cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da969dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
