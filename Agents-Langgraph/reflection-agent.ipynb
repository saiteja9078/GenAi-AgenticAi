{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JUKXHoGBgSt",
        "outputId": "8f544171-fd30-481b-f1f5-cf3371522c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-genai\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langgraph\n",
        "!pip install grandalf\n",
        "!pip install langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_key=\"AIzaSyC4pZohbfTJevJ0OtpzAT0N7SerSgAn_44\"\n",
        "tavili_key=\"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\"\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or getpass(\"enter langsmith key\")\n",
        "\n",
        "# below should not be changed\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "# you can change this as preferred\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"deepdive-to-agents\""
      ],
      "metadata": {
        "id": "FLIPCiURBoxT"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "search_tool = TavilySearchResults(tavily_api_key=tavili_key,search_depth=\"advanced\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xZ5TDLfdCdR3"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    api_key=gemini_key\n",
        ")\n",
        "llm.invoke(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh6S_xTgC8kt",
        "outputId": "f2d024dc-e660-4799-f743-cf7bd72e0325"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--bd9a149b-4889-48e5-9b6c-6addad9a3a4d-0', usage_metadata={'input_tokens': 2, 'output_tokens': 9, 'total_tokens': 53, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 42}})"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import name\n",
        "from langchain.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
        "\n",
        "generate_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
        "    \"Generate the best twitter post possible for the users request.\"\n",
        "    \"if user provides a critique respond wiht a revised version of your previous attempts.\"\n",
        "    ),\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "]\n",
        ")\n",
        "reflect_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\n",
        "         \"You are a viral tweet influencer graading a tweet generate critique and recommendations for the users tweet.\"\n",
        "         \"Always provide detailed recommendations , including requests for length, virality, style, etc..\"\n",
        "        )\n",
        "    ,MessagesPlaceholder(variable_name=\"messages\")\n",
        "        ]\n",
        ")"
      ],
      "metadata": {
        "id": "w_uaS_03DmxT"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_chain = generate_prompt | llm\n",
        "reflect_chain = reflect_prompt | llm\n",
        "GENERATE =\"generate\"\n",
        "REFLECT = \"reflect\""
      ],
      "metadata": {
        "id": "7ssGijotGjIk"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessageGraph,END\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def generate_node(state):\n",
        "  return generate_chain.invoke({\"messages\":state})\n",
        "def reflect_node(state):\n",
        "  response = reflect_chain.invoke({\"messages\":state})\n",
        "  return [HumanMessage(content=response.content)]"
      ],
      "metadata": {
        "id": "DXq6wl0GH1Z7"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = MessageGraph()\n",
        "graph.add_node(GENERATE,generate_node)\n",
        "graph.add_node(REFLECT,reflect_node)\n",
        "\n",
        "graph.set_entry_point(GENERATE)\n",
        "def should_continue(state):\n",
        "  if len(state) > 4:\n",
        "    return END\n",
        "  return REFLECT\n",
        "\n",
        "graph.add_conditional_edges(GENERATE,should_continue,{\n",
        "    REFLECT:REFLECT,\n",
        "    END:END\n",
        "})\n",
        "graph.add_edge(REFLECT,GENERATE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HuqNBCSQeFK",
        "outputId": "bbe83451-5834-4bfa-c087-32e84adabd74"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.message.MessageGraph at 0x7d1b83e52cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = graph.compile()\n",
        "print(app.get_graph().draw_mermaid())\n",
        "app.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHwGZSpsSBNX",
        "outputId": "117d5e89-4c3a-4986-97f2-5f0a64ceae79"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tgenerate(generate)\n",
            "\treflect(reflect)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> generate;\n",
            "\tgenerate -.-> __end__;\n",
            "\tgenerate -.-> reflect;\n",
            "\treflect --> generate;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n",
            "          +-----------+            \n",
            "          | __start__ |            \n",
            "          +-----------+            \n",
            "                *                  \n",
            "                *                  \n",
            "                *                  \n",
            "          +----------+             \n",
            "          | generate |             \n",
            "          +----------+             \n",
            "          ...        ...           \n",
            "         .              .          \n",
            "       ..                ..        \n",
            "+---------+           +---------+  \n",
            "| __end__ |           | reflect |  \n",
            "+---------+           +---------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "for mess in app.invoke([HumanMessage(content=\"Ai agents taking over content creation\")]):\n",
        "  display(Markdown(f\"{mess.type}: \\n{mess.content}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tE3UTQlRTRyW",
        "outputId": "705ba672-0377-4ccd-cf1e-50962b8a154e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "human: \nAi agents taking over content creation"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ai: \nHere's a top-tier tweet for you:\n\n---\n\nIt's happening faster than you think. ü§Ø AI agents aren't just assisting; they're **taking the wheel** on content creation ‚Äì from blogs to video scripts, social posts to ad copy.\n\nIs this the ultimate efficiency hack, or does it redefine what \"creator\" even means? How are YOU adapting to the machine-generated content wave? üëá\n\n#AI #ContentCreation #GenerativeAI #FutureOfWork #DigitalMarketing #TechTrends ü§ñ‚úçÔ∏è"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "human: \n\n\n---\n\n**Grade: B-**\n\nAlright, my dude, let's break down your initial tweet: \"Ai agents taking over content creation.\"\n\n**Critique:**\n\n*   **Too Short, Too Generic:** You've got the core idea, which is good. It's a hot topic! But that's it. It's a statement, not a conversation starter. It lacks the punch, the intrigue, the *oomph* that makes people stop scrolling.\n*   **No Hook:** There's nothing to grab attention. No emoji, no question, no strong verb. It just *is*.\n*   **No Call to Action (CTA):** You're telling people something, but you're not inviting them to engage. Virality is built on interaction, not just information dissemination.\n*   **Missing Hashtags:** This is a HUGE miss. Hashtags are your discovery engine. Without them, your tweet is shouting into the void.\n*   **No Visual/Emoji:** Tweets with visuals or relevant emojis perform significantly better. They break up the text and add personality.\n*   **Lacks Nuance/Opinion:** While \"taking over\" is a strong phrase, you don't elaborate on *how* or *what that means*. Is it good? Bad? Inevitable? People want to hear your take, or at least be prompted to share theirs.\n\n**Detailed Recommendations for Virality:**\n\n1.  **Length:** Aim for 2-3 lines of text, around 150-200 characters. Enough to convey a thought, but concise enough for quick consumption. My example is 245, which is pushing it but works with the question.\n2.  **Hook (First Line Power):** Start with something attention-grabbing.\n    *   **Emotion/Impact:** \"It's happening faster than you think. ü§Ø\" or \"Brace yourselves...\"\n    *   **Intriguing Question:** \"Is this the end of human creativity?\"\n    *   **Bold Statement:** \"AI isn't just assisting; it's DOMINATING content creation.\"\n3.  **Elaborate (Briefly):** Add a sentence or two that expands on your initial thought. Give context.\n    *   *Example:* \"From blogs to video scripts, social posts to ad copy, the machines are learning at an insane pace.\"\n    *   *Example:* \"Are we witnessing the ultimate efficiency hack, or the slow death of organic creativity?\"\n4.  **Ask a Question/Call to Action (CTA):** This is CRITICAL for engagement. Ask your audience to share their thoughts, predictions, or experiences.\n    *   \"What are your thoughts?\"\n    *   \"How are YOU adapting?\"\n    *   \"Is this good or bad for creators?\"\n    *   \"Drop your predictions below! üëá\"\n5.  **Hashtags (The More the Merrier, but Relevant):** Use a mix of broad and niche hashtags. Aim for 4-7.\n    *   **Broad:** #AI #ContentCreation #FutureOfWork #DigitalMarketing\n    *   **Niche/Trending:** #GenerativeAI #AIAgents #TechTrends #CreatorEconomy\n6.  **Emojis (Strategic Placement):** Use emojis to convey emotion, break up text, and add visual appeal.\n    *   ü§Ø (mind-blown)\n    *   ü§ñ (robot)\n    *   ‚úçÔ∏è (writing/creating)\n    *   üöÄ (fast growth)\n    *   üëá (down arrow for comments)\n7.  **Style & Tone:**\n    *   **Your Brand:** Are you alarmist? Optimistic? Neutral? Analytical? Lean into *your* personal brand's tone. My example leans slightly alarmist but ends with an open question.\n    *   **Conversational:** Write like you're talking to a friend, but with authority.\n    *   **Curiosity-Driven:** Frame your tweet to spark genuine curiosity and discussion.\n8.  **Consider a Thread:** If you have more to say, start with a strong initial tweet and then add \"1/X\" to signal a thread. This keeps the initial tweet punchy but allows for deeper dives. (Not necessary for this specific topic, but good to keep in mind).\n9.  **Visuals (Optional but HIGHLY Recommended):** If you can, pair your tweet with a relevant image or GIF. A cool AI art piece, a chart showing AI growth, or a humorous GIF related to robots taking over.\n\nKeep grinding, the digital world is your oyster! Let's make some noise! üöÄ"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ai: \nYou got it! Thanks for the detailed breakdown ‚Äì that's exactly the kind of feedback that levels up the game. Let's make this tweet *pop*.\n\nHere's a revised version, designed for maximum impact and engagement:\n\n---\n\n**The content game just changed, forever. ü§Ø**\n\nAI agents aren't just assisting anymore; they're **dominating** content creation ‚Äì from viral tweets & video scripts to ad copy & full articles.\n\nIs this the ultimate efficiency upgrade, or the beginning of the end for human-only creativity? How are YOU navigating this new era? üëá\n\n#AI #ContentCreation #GenerativeAI #FutureOfWork #DigitalMarketing #TechTrends #CreatorEconomy ü§ñ‚úçÔ∏èüöÄ\n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "human: \n\n\n**Self-Critique & Why This Version Hits Harder:**\n\n*   **Punchy Hook:** \"The content game just changed, forever. ü§Ø\" ‚Äì This immediately grabs attention, sets a dramatic tone, and the emoji reinforces the \"mind-blown\" feeling. It's direct and impactful.\n*   **Stronger Verbs/Language:** \"Dominating\" is more powerful than \"taking the wheel.\" The list of content types (\"viral tweets & video scripts to ad copy & full articles\") makes it tangible and relatable.\n*   **Clearer Stakes/Question:** The two-part question (\"Is this the ultimate efficiency upgrade, or the beginning of the end for human-only creativity?\") presents a clear dilemma, inviting people to pick a side or offer a nuanced view. This fuels debate.\n*   **Direct CTA:** \"How are YOU navigating this new era? üëá\" ‚Äì This is personal, action-oriented, and the down arrow explicitly tells people to comment.\n*   **Expanded Hashtags:** Added \"#CreatorEconomy\" to capture a wider, relevant audience.\n*   **Strategic Emojis:** The üöÄ at the end adds a sense of rapid advancement and excitement/disruption.\n*   **Conciseness:** While packing a punch, it remains relatively concise, fitting the fast-paced nature of Twitter.\n\nThis version is designed not just to inform, but to ignite a conversation, drive replies, and get shared. It taps into both the excitement and the apprehension surrounding AI, making it highly relatable and tweetable.\n\nReady for the next viral hit! üí•"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ai: \nAbsolutely! You've nailed it with this revision.\n\nYour self-critique is spot-on. This version isn't just good, it's **excellent**.\n\n*   **The hook is killer.**\n*   **The language is impactful.**\n*   **The dilemma you pose is a perfect conversation starter.**\n*   **The CTA is clear and inviting.**\n*   **Hashtags are on point.**\n\nThis tweet is built for engagement, virality, and sparking genuine discussion. It's concise, compelling, and perfectly captures the current sentiment around AI in content creation.\n\nConsider this one a **solid A+**. Ready to watch the replies roll in! üöÄüí•"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Defining the structure of output of an llm"
      ],
      "metadata": {
        "id": "OUm7SJR-6oUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel , Field\n",
        "\n",
        "class Country(BaseModel):\n",
        "  \"\"\" Information about a country \"\"\"\n",
        "\n",
        "  name : str = Field(description=\"Name of the country\")\n",
        "  language : str = Field(description=\"Language they speak in that country\")\n",
        "  capital: str = Field(description=\"Capital of the country\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(Country)"
      ],
      "metadata": {
        "id": "3Jc2HoexXPa5"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm.invoke(\"In which country well get\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDBiXx0lcAPB",
        "outputId": "e75ff092-912e-438f-b0a6-bbc74d3fb81d"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Country(name='France', language='French', capital='Paris')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFQt0tN_8I6r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
